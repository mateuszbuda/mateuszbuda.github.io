---
title: "Segmentation of brain tumor in magnetic resonance images"
description: "We applied U-Net architecture for the task of whole tumor segmentation in brain MRI.
The dataset used for development was obtained from The Cancer Imaging Archive (TCIA) and involved 110 cases of lower-grade glioma patients.
To evaluate the quality of segmentation, we used Dice similarity coefficient (DSC) with 22-fold cross-validation.
The achieved performance was 83.60% mean DSC and 87.33% median DSC.
In comparison, DSC of two expert human readers for this kind of tumor is 84% with a standard deviation of 2%.
This puts our method on a par with radiologists."
---

The dataset used for development was obtained from The Cancer Imaging Archive (<a href="https://wiki.cancerimagingarchive.net/display/Public/TCGA-LGG" target="_blank">TCIA</a>) and involved 110 cases of lower-grade glioma patients.
Registers brain MR images with manual FLAIR abnormality segmentation masks are published as a Kaggle Dataset <a href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" target="_blank">lgg-mri-segmentation</a>.

<p style="text-align: center">
    <img src="/images/brainseg/brain-mri-lgg.png" alt="Brain MRI Dataset" width="96%">
</p>

Together with the dataset, we shared a GPU enabled Python code that can be run on Kaggle: <a href="https://www.kaggle.com/mateuszbuda/brain-segmentation-pytorch" target="_blank">kaggle.com/mateuszbuda/brain-segmentation-pytorch</a>.
The script implements a data loading, preprocessing, as well as training and inference of a U-Net segmentation model.
Trained weights and results can be downloaded form Kaggle.

We applied U-Net architecture for the task of FLAIR abnormality segmentation in brain MRI (Figure 1).
Source code for network architecture, training, and inference implemented in PyTorch together with model weights are available on GitHub repository: <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch" target="_blank">github.com/mateuszbuda/brain-segmentation-pytorch</a>.

<p style="text-align: center">
	<img src="/images/brainseg/unet.png" alt="U-Net" width="96%">
</p>
Figure 1. The U-Net architecture used for segmentation.


To evaluate the quality of segmentation, we used Dice similarity coefficient (DSC) with 22-fold cross-validation.
The achieved performance was 83.60% mean DSC and 87.33% median DSC.
In comparison, DSC of two expert human readers for this kind of tumor is 84% with a standard deviation of 2%.
This puts our method on a par with radiologists.

<p style="text-align: center">
	<img src="/images/brainseg/CS_4942.gif" alt="CS_4942" width="30%">
	<img src="/images/brainseg/CS_5395.gif" alt="CS_5395" width="30%">
	<img src="/images/brainseg/CS_6668.gif" alt="CS_6668" width="30%">
</p>
Figure 2. Qualitative results of segmentation.
Blue outline corresponds to ground truth and red to automatic segmentation output.
Images show FLAIR modality after preprocessing and skull stripping.

<p style="text-align: center">
	<img src="/images/brainseg/DSC_distribution.png" alt="DSC distribution" width="96%">
</p>
Figure 3. Distribution of Dice similarity coefficient among cases.
Red line corresponds to mean DSC and green to median DSC.

Then, produced segmentations were used to extract 2D and 3D tumor shape features that are predictive of its genomic subtypes.
More detailed description of methods and results is available in our paper <i><a href="https://doi.org/10.1016/j.compbiomed.2019.05.002" target="_blank">Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm</a></i> published in Computers in Biology and Medicine.

<p style="text-align: center">
    <img src="/images/brainseg/abstract.png" alt="Graphical Abstract" width="96%">
</p>

### Links

- Full paper: <a href="https://doi.org/10.1016/j.compbiomed.2019.05.002" target="_blank">Computers in Biology and Medicine</a>
- Code: <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch" target="_blank">github.com/mateuszbuda/brain-segmentation-pytorch</a>
- Data: <a href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" target="_blank">lgg-mri-segmentation</a>
